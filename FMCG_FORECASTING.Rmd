---
title: "Untitled"
author: "Daniel"
date: "6/2/2021"
output: html_document
---



```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  comment = "#>"
)

options(scipen = 999)
```

# Library

```{r}
library(dplyr) # for data wrangling
library(lubridate) # to dea with date
library(padr) # for padding
library(forecast) # time series library
library(tseries) # for adf.test
library(MLmetrics) # calculate error
library(zoo) #imputation missing value
library(tseries) # adf.test
```


# Read Data

```{r}
fmcg <- read.csv("data.csv")
glimpse(fmcg)
```

Data Description :
date : date of sales obsevation
product_identifier : the id for a product
department_identifier : The id for spesific department in a store
category_of_product : The category to which a product belongs
outlet : The id for a store
state : The name of the state
sales : The number of sales product

```{r}
fmcg <- fmcg %>% 
  mutate(category_of_product = as.factor(category_of_product),
         state = as.factor(state),
         date = ymd(date))
glimpse(fmcg)
```


> Data Agregation

```{r}
head(fmcg)
```


From the data set we just concern to sales forecast in fmcg, so we must to get date and sales from fmcg category product

```{r}
fmcg_data <- fmcg %>% 
             filter(category_of_product == "fast_moving_consumer_goods") %>% 
             select(date,sales)

fmcg_data
```

```{r}
daily_fmcg <- fmcg_data %>% 
  group_by(date) %>% 
  summarise(sales = sum(sales)) %>% 
  arrange(date)
daily_fmcg
```

Data time series yang baik adalah memiliki data yang berurut dan tidak kosong, oleh sebab itu dengan menggunakan pad, akan melakukan pengecekan tiap baris data apakah ada yang kosong atau tidak.


```{r}
daily_fmcg %>% filter(sales == 0)
```

```{r}
daily_fmcg <- daily_fmcg[daily_fmcg$sales > 0, ]
daily_fmcg %>% filter(sales == 0 )
```



```{r}
daily_fmcg %>% 
  arrange(date) %>% 
  pad() %>% 
  na.locf()
            
```


```{r}
range(daily_fmcg$date)
```
# Time Series object & EDA

```{r}
fmcg_ts <- ts(data = daily_fmcg$sales,
              start = range(daily_fmcg$date)[[1]],
              frequency = 7) #weekly seasonality
```

Pada proses ini saya akan melakukan analisa untuk mengetahui apakah data bersifat seasonal dan trend, satu seasonal atau lebih dari satu seasonal

```{r}
fmcg_decom <- decompose(fmcg_ts)
autoplot(fmcg_decom)
```

Dari hasil plot diatas dapat dikatakan bahwa data memiliki multiseasonal, dan pola data trend menunjukan pola multiseasonal

```{r}
#making 2nd ts object
daily_fmcg$sales %>% 
  msts(seasonal.periods = c(7,7*4)) %>%  # multiseasonal ts (weekly, monthly)
  mstl() %>% #multiseasonal ts decomposotion
  autoplot()
```

```{r}
#making 3nd ts object
daily_fmcg$sales %>% 
  msts(seasonal.periods = c(7*4*3, 7*4*12)) %>%  # multiseasonal ts (quarterly, yearly)
  mstl() %>% #multiseasonal ts decomposotion
  autoplot()
```

objek terakhir adalah dengan melakukan tiga percobaan time series model, dan model time series terakhir adalah model yang cocok dengan dua seasonal dan trend yang memiliki pola turun.

```{r}
#assign final ts object
fmcg_msts <- daily_fmcg$sales %>% 
  msts(seasonal.periods = c(7*4*3, 7*4*12))

# check for stationary
adf.test(fmcg_msts)
```

Based on Augmented Dickey-Fuller Test (adf.test) result, the p-value is < alpha and therefore the data is already stationary. Therefore, for a model building using SARIMA, we do not need to perform differencing on the data first.


# Cross Validation

```{r}
fmcg_train <- function(x){
  train <- head(x, length(x) - 7*4)
}

fmcg_test <- function(x){
  test <- tail(x, 7*4)
}

train_1 <- fmcg_train(fmcg_msts)
test_1 <- fmcg_test(fmcg_msts) 
```


# Model Building

Untuk pembuatan model kita akan mengkompare antara ets holt winters dengan Seasonal Arima, karena data memiliki seasonal dan juga trend   

Ada salah satu cara untuk mendapatkan decompose data namun tetap mempertahankan informasi dari seluruh data yang kita miliki yaitu dengan menggunakan **STL (Seasonal Trend with Loess)**. STL secara konsep akan melakukan smoothing terhadap data tetangga setiap masing-masing observasi dengan memberikan bobot yang lebih berat terhadap data yang dekat dengan observed data.   

Untuk memodelkan hasil STL, kita juga dapat menerapkan metode exponential smoothing (ETS) dan ARIMA. Selain itu, STLM dapat digunakan sebagai alternative cara untuk menangkap seasonal yang belum bisa ditangkap oleh metode ETS dan ARIMA biasa. 

```{r}
#ets Holt - Winters
fmcg_ets <- stlm(train_1, method = "ets", lambda = 0) # no log transformation for addivite data

# SARIMA
fmcg_arima <- stlm(train_1, method = "arima", lambda = 0)

```


# Forecas & Evaluation

```{r}
compare_forecast <- function(x, test){
  lapply(x, function(x) forecast::accuracy(x, test)["Test set", ]) %>%
    lapply(., function(x) x %>% t() %>% as.data.frame) %>% 
    bind_rows() %>% 
    mutate(model = names(x)) %>%
    select(model, everything())
}
```


```{r}
#Forecast
forecast_ets <- forecast(object = fmcg_ets, h = length(test_1))
forecast_arima <- forecast(object = fmcg_arima, h = length(test_1))
```



```{r}
#Evaluation
forecast_list <- list(
  "ETS" = forecast_ets,
  "Arima" = forecast_arima
)
compare_forecast(forecast_list,test_1 )
```

> Arima the best modell

```{r}
fmcg_msts %>% 
  autoplot(series = "Actual") +
  autolayer(forecast_ets$mean, series = "ETS") + 
  autolayer(forecast_arima$mean, series = "ARIMA")
```

# Shapiro Test

```{r}
shapiro.test(forecast_arima$residuals)
```

```{r}
hist(forecast_arima$residuals, breaks = 50)
```


```{r}
TSstudio::test_forecast(actual = fmcg_msts, 
              forecast.obj = forecast_arima, 
              train = train_1, 
              test = test_1)
```



>>>>>>>>>>>>>>>>>>>> TEST

```{r}
model_fmcg <- fmcg_msts
```

> Data predict

```{r}
predict <- read.csv("test_data.csv")
head(predict)
```

```{r}
predict <- predict %>% 
  filter(category_of_product == "fast_moving_consumer_goods") %>% 
  select(-id)
```


```{r}
predict_clean <- predict %>% mutate(date = ymd(date))
```

```{r}
predict_forecast <- predict_clean[!duplicated(predict_clean$date),] %>% 
  select(date)
predict_forecast
```

# MODEL

```{r}
arima_model <- stlm(model_fmcg, method = "arima", lambda = 0)

#forecast
arima_f <- forecast(arima_model, h = 31)
```

```{r}
model_fmcg %>% 
  autoplot(series = "Actual") +
  autolayer(arima_f$mean, series = "Forecast")
```
# Data frame

```{r}
predict_forecast %>% 
  cbind(arima_f) %>% as.data.frame()
```









